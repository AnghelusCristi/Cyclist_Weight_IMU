{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "75940fcebf4ae395"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:04.550506Z",
     "start_time": "2024-06-15T11:03:04.538817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier   \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "id": "23e953646e19ca4b",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.337903Z",
     "start_time": "2024-06-15T11:03:05.504546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import only the high speed data\n",
    "df = pd.read_csv('Data/combined_data.csv')\n",
    "df_high = df[df['speed'] == 2].copy()"
   ],
   "id": "5783f0f4fcabb9b",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.572887Z",
     "start_time": "2024-06-15T11:03:20.341910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Divide the data into classes based on weight.\n",
    "num_classes = 8\n",
    "df_high.loc[:, 'weight_class'] = pd.qcut(df_high['weight'], q=num_classes, labels=False)"
   ],
   "id": "e8acc4398f00f197",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.824884Z",
     "start_time": "2024-06-15T11:03:20.575891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group the DataFrame by 'weight_class' and get unique 'weight' in each group\n",
    "weights_by_class= df_high.groupby('weight_class')['weight'].unique()\n",
    "\n",
    "print(weights_by_class)"
   ],
   "id": "e02c26382a0d427d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_class\n",
      "0     [84.5, 86.25]\n",
      "1    [87.35, 89.15]\n",
      "2     [90.5, 91.95]\n",
      "3      [93.4, 94.7]\n",
      "4      [96.3, 97.5]\n",
      "5     [99.1, 100.5]\n",
      "6    [101.7, 103.0]\n",
      "7    [104.3, 105.7]\n",
      "Name: weight, dtype: object\n"
     ]
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.856381Z",
     "start_time": "2024-06-15T11:03:20.835385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_test():\n",
    "    # Split the data into training and testing sets\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "    weights_by_class = df_high.groupby('weight_class')['weight'].unique()\n",
    "    \n",
    "    for weight_class, weights in weights_by_class.items():\n",
    "        weights = sorted(weights)\n",
    "        test_weights = [weights[0]]  # Select the testing weights\n",
    "        train_weights = [weight for i, weight in enumerate(weights) if i not in [0]]  # Exclude the testing weights\n",
    "        \n",
    "        df_test = pd.concat([df_test, df_high[(df_high['weight_class'] == weight_class) & (df_high['weight'].isin(test_weights))]], ignore_index=True)\n",
    "        for weight in train_weights:\n",
    "            df_train = pd.concat([df_train, df_high[(df_high['weight_class'] == weight_class) & (df_high['weight'] == weight)]], ignore_index=True)\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    return df_train, df_test"
   ],
   "id": "510683efad21755c",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract features",
   "id": "4bfeea3b40822715"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.920384Z",
     "start_time": "2024-06-15T11:03:20.858382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature extraction function\n",
    "# Credit to: https://towardsdatascience.com/feature-engineering-on-time-series-data-transforming-signal-data-of-a-smartphone-accelerometer-for-72cbe34b8a60\n",
    "\n",
    "def extract_features(df, window_size, step_size):\n",
    "    ax_list, ay_list, az_list, labels = [], [], [], []\n",
    "    for i in range(0, df.shape[0] - window_size, step_size):\n",
    "        axs = df['ax'].values[i: i + window_size]\n",
    "        ays = df['ay'].values[i: i + window_size]\n",
    "        azs = df['az'].values[i: i + window_size]\n",
    "        label = df['weight_class'].iloc[i: i + window_size].mode()[0]\n",
    "        \n",
    "        ax_list.append(axs)\n",
    "        ay_list.append(ays)\n",
    "        az_list.append(azs)\n",
    "        labels.append(label)\n",
    "    \n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    X['x_mean'] = pd.Series(ax_list).apply(lambda x: x.mean())\n",
    "    X['y_mean'] = pd.Series(ay_list).apply(lambda x: x.mean())\n",
    "    X['z_mean'] = pd.Series(az_list).apply(lambda x: x.mean())\n",
    "\n",
    "    X['x_std'] = pd.Series(ax_list).apply(lambda x: x.std())\n",
    "    X['y_std'] = pd.Series(ay_list).apply(lambda x: x.std())\n",
    "    X['z_std'] = pd.Series(az_list).apply(lambda x: x.std())\n",
    "\n",
    "    X['x_aad'] = pd.Series(ax_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['y_aad'] = pd.Series(ay_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['z_aad'] = pd.Series(az_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    X['x_min'] = pd.Series(ax_list).apply(lambda x: x.min())\n",
    "    X['y_min'] = pd.Series(ay_list).apply(lambda x: x.min())\n",
    "    X['z_min'] = pd.Series(az_list).apply(lambda x: x.min())\n",
    "\n",
    "    X['x_max'] = pd.Series(ax_list).apply(lambda x: x.max())\n",
    "    X['y_max'] = pd.Series(ay_list).apply(lambda x: x.max())\n",
    "    X['z_max'] = pd.Series(az_list).apply(lambda x: x.max())\n",
    "\n",
    "    X['x_maxmin_diff'] = X['x_max'] - X['x_min']\n",
    "    X['y_maxmin_diff'] = X['y_max'] - X['y_min']\n",
    "    X['z_maxmin_diff'] = X['z_max'] - X['z_min']\n",
    "    \n",
    "    X['x_median'] = pd.Series(ax_list).apply(lambda x: np.median(x))\n",
    "    X['y_median'] = pd.Series(ay_list).apply(lambda x: np.median(x))\n",
    "    X['z_median'] = pd.Series(az_list).apply(lambda x: np.median(x))\n",
    "    \n",
    "    X['x_mad'] = pd.Series(ax_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['y_mad'] = pd.Series(ay_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['z_mad'] = pd.Series(az_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    \n",
    "    X['x_IQR'] = pd.Series(ax_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['y_IQR'] = pd.Series(ay_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['z_IQR'] = pd.Series(az_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    \n",
    "    X['x_neg_count'] = pd.Series(ax_list).apply(lambda x: np.sum(x < 0))\n",
    "    X['y_neg_count'] = pd.Series(ay_list).apply(lambda x: np.sum(x < 0))\n",
    "    X['z_neg_count'] = pd.Series(az_list).apply(lambda x: np.sum(x < 0))\n",
    "    \n",
    "    X['x_pos_count'] = pd.Series(ax_list).apply(lambda x: np.sum(x > 0))\n",
    "    X['y_pos_count'] = pd.Series(ay_list).apply(lambda x: np.sum(x > 0))\n",
    "    X['z_pos_count'] = pd.Series(az_list).apply(lambda x: np.sum(x > 0))\n",
    "    \n",
    "    X['x_above_mean'] = pd.Series(ax_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['y_above_mean'] = pd.Series(ay_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['z_above_mean'] = pd.Series(az_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    \n",
    "    X['x_peak_count'] = pd.Series(ax_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['y_peak_count'] = pd.Series(ay_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['z_peak_count'] = pd.Series(az_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    \n",
    "    X['x_skewness'] = pd.Series(ax_list).apply(lambda x: stats.skew(x))\n",
    "    X['y_skewness'] = pd.Series(ay_list).apply(lambda x: stats.skew(x))\n",
    "    X['z_skewness'] = pd.Series(az_list).apply(lambda x: stats.skew(x))\n",
    "    \n",
    "    X['x_kurtosis'] = pd.Series(ax_list).apply(lambda x: stats.kurtosis(x))\n",
    "    X['y_kurtosis'] = pd.Series(ay_list).apply(lambda x: stats.kurtosis(x))\n",
    "    X['z_kurtosis'] = pd.Series(az_list).apply(lambda x: stats.kurtosis(x))\n",
    "    \n",
    "    X['x_energy'] = pd.Series(ax_list).apply(lambda x: np.sum(x**2)/100)\n",
    "    X['y_energy'] = pd.Series(ay_list).apply(lambda x: np.sum(x**2)/100)\n",
    "    X['z_energy'] = pd.Series(az_list).apply(lambda x: np.sum(x**2/100))\n",
    "    \n",
    "    X['avg_result_accl'] = [i.mean() for i in ((pd.Series(ax_list)**2 + pd.Series(ay_list)**2 + pd.Series(az_list)**2)**0.5)]\n",
    "    X['sma'] = pd.Series(ax_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(ay_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(az_list).apply(lambda x: np.sum(abs(x)/100))\n",
    "    \n",
    "    # FFT features\n",
    "    x_list_fft = pd.Series(ax_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    y_list_fft = pd.Series(ay_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    z_list_fft = pd.Series(az_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    \n",
    "    X['x_mean_fft'] = x_list_fft.apply(lambda x: x.mean())\n",
    "    X['y_mean_fft'] = y_list_fft.apply(lambda x: x.mean())\n",
    "    X['z_mean_fft'] = z_list_fft.apply(lambda x: x.mean())\n",
    "    \n",
    "    X['x_std_fft'] = x_list_fft.apply(lambda x: x.std())\n",
    "    X['y_std_fft'] = y_list_fft.apply(lambda x: x.std())\n",
    "    X['z_std_fft'] = z_list_fft.apply(lambda x: x.std())\n",
    "    \n",
    "    X['x_aad_fft'] = x_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['y_aad_fft'] = y_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['z_aad_fft'] = z_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    \n",
    "    X['x_min_fft'] = x_list_fft.apply(lambda x: x.min())\n",
    "    X['y_min_fft'] = y_list_fft.apply(lambda x: x.min())\n",
    "    X['z_min_fft'] = z_list_fft.apply(lambda x: x.min())\n",
    "    \n",
    "    X['x_max_fft'] = x_list_fft.apply(lambda x: x.max())\n",
    "    X['y_max_fft'] = y_list_fft.apply(lambda x: x.max())\n",
    "    X['z_max_fft'] = z_list_fft.apply(lambda x: x.max())\n",
    "    \n",
    "    X['x_maxmin_diff_fft'] = X['x_max_fft'] - X['x_min_fft']\n",
    "    X['y_maxmin_diff_fft'] = X['y_max_fft'] - X['y_min_fft']\n",
    "    X['z_maxmin_diff_fft'] = X['z_max_fft'] - X['z_min_fft']\n",
    "    \n",
    "    X['x_median_fft'] = x_list_fft.apply(lambda x: np.median(x))\n",
    "    X['y_median_fft'] = y_list_fft.apply(lambda x: np.median(x))\n",
    "    X['z_median_fft'] = z_list_fft.apply(lambda x: np.median(x))\n",
    "    \n",
    "    X['x_mad_fft'] = x_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['y_mad_fft'] = y_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['z_mad_fft'] = z_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    \n",
    "    X['x_IQR_fft'] = x_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['y_IQR_fft'] = y_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['z_IQR_fft'] = z_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    \n",
    "    X['x_above_mean_fft'] = x_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['y_above_mean_fft'] = y_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['z_above_mean_fft'] = z_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    X['x_peak_count_fft'] = x_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['y_peak_count_fft'] = y_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['z_peak_count_fft'] = z_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    X['x_skewness_fft'] = x_list_fft.apply(lambda x: stats.skew(x))\n",
    "    X['y_skewness_fft'] = y_list_fft.apply(lambda x: stats.skew(x))\n",
    "    X['z_skewness_fft'] = z_list_fft.apply(lambda x: stats.skew(x))\n",
    "    \n",
    "    X['x_kurtosis_fft'] = x_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    X['y_kurtosis_fft'] = y_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    X['z_kurtosis_fft'] = z_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    \n",
    "    X['x_energy_fft'] = x_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    X['y_energy_fft'] = y_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    X['z_energy_fft'] = z_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    \n",
    "    X['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft)**2 + pd.Series(y_list_fft)**2 + pd.Series(z_list_fft)**2)**0.5)]\n",
    "    \n",
    "    X['sma_fft'] = x_list_fft.apply(lambda x: np.sum(abs(x)/50)) + y_list_fft.apply(lambda x: np.sum(abs(x)/50)) + z_list_fft.apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "    # X['speed'] = df['speed']\n",
    "    # X['node-id'] = df['node-id']\n",
    "    \n",
    "    y = np.array(labels)\n",
    "    return X, y\n"
   ],
   "id": "512e910d2c895463",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.935385Z",
     "start_time": "2024-06-15T11:03:20.922392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ],
   "id": "b784cfc4baf549f3",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.950385Z",
     "start_time": "2024-06-15T11:03:20.938389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_classification_report(y_true, y_pred, filename):\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(report)"
   ],
   "id": "39a986ff8707cc18",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:20.965383Z",
     "start_time": "2024-06-15T11:03:20.953385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating overlapping windows of size window-size 400 (200 hz * 2 seconds = 400 frame windows for 2 seconds)\n",
    "window_size = 400\n",
    "step_size = int(window_size * 0.5)"
   ],
   "id": "a41cbba35d40eb74",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models",
   "id": "cc1491c0e944e589"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### All sensors",
   "id": "87ce8cb8d32b7dfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:06:03.859951Z",
     "start_time": "2024-06-15T11:03:20.968385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "eb7b2e90dedadbe8",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:06:33.406621Z",
     "start_time": "2024-06-15T11:06:03.866488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - All sensors', 'Results/High_speed/{0} classes/knn_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/High_speed/{0} classes/knn_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - All sensors', 'Results/High_speed/{0} classes/dt_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/High_speed/{0} classes/dt_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - All sensors', 'Results/High_speed/{0} classes/svm_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/High_speed/{0} classes/svm_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - All sensors', 'Results/High_speed/{0} classes/lr_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/High_speed/{0} classes/lr_all_sensors.txt'.format(num_classes))"
   ],
   "id": "5fec3c73e58ff65f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.16323978883023063\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.39      0.27       900\n",
      "           1       0.15      0.23      0.19       900\n",
      "           2       0.14      0.14      0.14       900\n",
      "           3       0.17      0.17      0.17       900\n",
      "           4       0.12      0.11      0.11       900\n",
      "           5       0.10      0.07      0.08       900\n",
      "           6       0.17      0.09      0.12       900\n",
      "           7       0.21      0.10      0.14       898\n",
      "\n",
      "    accuracy                           0.16      7198\n",
      "   macro avg       0.16      0.16      0.15      7198\n",
      "weighted avg       0.16      0.16      0.15      7198\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.20519588774659628\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.31      0.28       900\n",
      "           1       0.21      0.24      0.22       900\n",
      "           2       0.23      0.24      0.24       900\n",
      "           3       0.21      0.21      0.21       900\n",
      "           4       0.17      0.17      0.17       900\n",
      "           5       0.12      0.12      0.12       900\n",
      "           6       0.20      0.20      0.20       900\n",
      "           7       0.23      0.16      0.18       898\n",
      "\n",
      "    accuracy                           0.21      7198\n",
      "   macro avg       0.20      0.21      0.20      7198\n",
      "weighted avg       0.20      0.21      0.20      7198\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.19560989163656572\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.49      0.35       900\n",
      "           1       0.19      0.22      0.20       900\n",
      "           2       0.18      0.18      0.18       900\n",
      "           3       0.18      0.17      0.17       900\n",
      "           4       0.12      0.08      0.10       900\n",
      "           5       0.12      0.10      0.11       900\n",
      "           6       0.23      0.16      0.19       900\n",
      "           7       0.20      0.15      0.17       898\n",
      "\n",
      "    accuracy                           0.20      7198\n",
      "   macro avg       0.19      0.20      0.18      7198\n",
      "weighted avg       0.19      0.20      0.18      7198\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.19686023895526536\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.48      0.34       900\n",
      "           1       0.19      0.21      0.20       900\n",
      "           2       0.18      0.17      0.18       900\n",
      "           3       0.18      0.18      0.18       900\n",
      "           4       0.12      0.08      0.09       900\n",
      "           5       0.12      0.11      0.11       900\n",
      "           6       0.24      0.17      0.20       900\n",
      "           7       0.21      0.19      0.20       898\n",
      "\n",
      "    accuracy                           0.20      7198\n",
      "   macro avg       0.19      0.20      0.19      7198\n",
      "weighted avg       0.19      0.20      0.19      7198\n",
      "\n"
     ]
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "70ec7de9a19b45f5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 561 - On the head tube",
   "id": "28339ce86ac8d3ae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:06:36.151103Z",
     "start_time": "2024-06-15T11:06:33.409612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 561\n",
    "df_train = df_train[df_train['node-id'] == 561]\n",
    "df_test = df_test[df_test['node-id'] == 561]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "127a87217deb241",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:07:37.186559Z",
     "start_time": "2024-06-15T11:06:36.153606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "1b73db7fa9da3233",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:07:44.485812Z",
     "start_time": "2024-06-15T11:07:37.189530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 561', 'Results/High_speed/{0} classes/knn_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/High_speed/{0} classes/knn_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 561', 'Results/High_speed/{0} classes/dt_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/High_speed/{0} classes/dt_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 561', 'Results/High_speed/{0} classes/svm_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/High_speed/{0} classes/svm_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 561', 'Results/High_speed/{0} classes/lr_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/High_speed/{0} classes/lr_sensor_561.txt'.format(num_classes))"
   ],
   "id": "7737e9838f17a0f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.17264386989157632\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.46      0.30       300\n",
      "           1       0.15      0.20      0.17       300\n",
      "           2       0.11      0.09      0.10       300\n",
      "           3       0.21      0.15      0.17       300\n",
      "           4       0.16      0.16      0.16       300\n",
      "           5       0.12      0.10      0.11       300\n",
      "           6       0.18      0.11      0.14       300\n",
      "           7       0.19      0.12      0.14       298\n",
      "\n",
      "    accuracy                           0.17      2398\n",
      "   macro avg       0.17      0.17      0.16      2398\n",
      "weighted avg       0.17      0.17      0.16      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.16013344453711426\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.26      0.25       300\n",
      "           1       0.20      0.22      0.21       300\n",
      "           2       0.18      0.18      0.18       300\n",
      "           3       0.21      0.17      0.19       300\n",
      "           4       0.12      0.16      0.14       300\n",
      "           5       0.10      0.09      0.10       300\n",
      "           6       0.13      0.13      0.13       300\n",
      "           7       0.10      0.08      0.09       298\n",
      "\n",
      "    accuracy                           0.16      2398\n",
      "   macro avg       0.16      0.16      0.16      2398\n",
      "weighted avg       0.16      0.16      0.16      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.1939115929941618\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.47      0.36       300\n",
      "           1       0.20      0.22      0.21       300\n",
      "           2       0.22      0.30      0.25       300\n",
      "           3       0.16      0.13      0.15       300\n",
      "           4       0.12      0.09      0.11       300\n",
      "           5       0.09      0.08      0.08       300\n",
      "           6       0.22      0.16      0.19       300\n",
      "           7       0.14      0.09      0.11       298\n",
      "\n",
      "    accuracy                           0.19      2398\n",
      "   macro avg       0.18      0.19      0.18      2398\n",
      "weighted avg       0.18      0.19      0.18      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.19766472060050042\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.46      0.35       300\n",
      "           1       0.19      0.18      0.18       300\n",
      "           2       0.21      0.27      0.24       300\n",
      "           3       0.18      0.17      0.18       300\n",
      "           4       0.13      0.09      0.11       300\n",
      "           5       0.10      0.08      0.09       300\n",
      "           6       0.22      0.21      0.22       300\n",
      "           7       0.16      0.11      0.13       298\n",
      "\n",
      "    accuracy                           0.20      2398\n",
      "   macro avg       0.18      0.20      0.19      2398\n",
      "weighted avg       0.18      0.20      0.19      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 562 - Under the seat",
   "id": "76dd3e50eac43311"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:07:47.632659Z",
     "start_time": "2024-06-15T11:07:44.489805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 562\n",
    "df_train = df_train[df_train['node-id'] == 562]\n",
    "df_test = df_test[df_test['node-id'] == 562]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "8a2ca87e3b5454e5",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:08:47.808317Z",
     "start_time": "2024-06-15T11:07:47.636561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "727d8736fa3a2f6",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:08:54.014827Z",
     "start_time": "2024-06-15T11:08:47.811313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 562', 'Results/High_speed/{0} classes/knn_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/High_speed/{0} classes/knn_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 562', 'Results/High_speed/{0} classes/dt_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/High_speed/{0} classes/dt_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 562', 'Results/High_speed/{0} classes/svm_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/High_speed/{0} classes/svm_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 562', 'Results/High_speed/{0} classes/lr_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/High_speed/{0} classes/lr_sensor_562.txt'.format(num_classes))"
   ],
   "id": "d2aae0e02faa4605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.22768974145120935\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.45      0.34       300\n",
      "           1       0.19      0.27      0.23       300\n",
      "           2       0.18      0.21      0.19       300\n",
      "           3       0.27      0.29      0.28       300\n",
      "           4       0.17      0.18      0.17       300\n",
      "           5       0.19      0.13      0.16       300\n",
      "           6       0.29      0.19      0.23       300\n",
      "           7       0.52      0.09      0.15       298\n",
      "\n",
      "    accuracy                           0.23      2398\n",
      "   macro avg       0.26      0.23      0.22      2398\n",
      "weighted avg       0.26      0.23      0.22      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.2889908256880734\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.51      0.44       300\n",
      "           1       0.23      0.26      0.24       300\n",
      "           2       0.31      0.33      0.32       300\n",
      "           3       0.24      0.24      0.24       300\n",
      "           4       0.25      0.26      0.26       300\n",
      "           5       0.17      0.18      0.17       300\n",
      "           6       0.29      0.33      0.31       300\n",
      "           7       0.69      0.20      0.32       298\n",
      "\n",
      "    accuracy                           0.29      2398\n",
      "   macro avg       0.32      0.29      0.29      2398\n",
      "weighted avg       0.32      0.29      0.29      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.3244370308590492\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.58      0.48       300\n",
      "           1       0.31      0.39      0.35       300\n",
      "           2       0.37      0.39      0.38       300\n",
      "           3       0.30      0.30      0.30       300\n",
      "           4       0.33      0.32      0.32       300\n",
      "           5       0.19      0.15      0.17       300\n",
      "           6       0.27      0.37      0.31       300\n",
      "           7       0.61      0.09      0.16       298\n",
      "\n",
      "    accuracy                           0.32      2398\n",
      "   macro avg       0.35      0.32      0.31      2398\n",
      "weighted avg       0.35      0.32      0.31      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.33069224353628024\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.63      0.51       300\n",
      "           1       0.29      0.35      0.31       300\n",
      "           2       0.36      0.37      0.36       300\n",
      "           3       0.28      0.26      0.27       300\n",
      "           4       0.32      0.30      0.31       300\n",
      "           5       0.20      0.17      0.18       300\n",
      "           6       0.30      0.40      0.34       300\n",
      "           7       0.69      0.16      0.26       298\n",
      "\n",
      "    accuracy                           0.33      2398\n",
      "   macro avg       0.36      0.33      0.32      2398\n",
      "weighted avg       0.36      0.33      0.32      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 563 - Rear frame",
   "id": "30539c6cbf41002"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:08:56.812954Z",
     "start_time": "2024-06-15T11:08:54.018829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 561\n",
    "df_train = df_train[df_train['node-id'] == 563]\n",
    "df_test = df_test[df_test['node-id'] == 563]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "3b0e6cd8a67b6a8e",
   "outputs": [],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:10:00.219305Z",
     "start_time": "2024-06-15T11:08:56.819520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "5803dafa1c5263d7",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:10:08.245111Z",
     "start_time": "2024-06-15T11:10:00.221287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 563', 'Results/High_speed/{0} classes/knn_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/High_speed/{0} classes/knn_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 563', 'Results/High_speed/{0} classes/dt_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/High_speed/{0} classes/dt_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 563', 'Results/High_speed/{0} classes/svm_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/High_speed/{0} classes/svm_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 563', 'Results/High_speed/{0} classes/lr_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/High_speed/{0} classes/lr_sensor_563.txt'.format(num_classes))"
   ],
   "id": "834d20bd34096c0e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.16930775646371976\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.42      0.28       300\n",
      "           1       0.15      0.19      0.16       300\n",
      "           2       0.18      0.17      0.17       300\n",
      "           3       0.21      0.21      0.21       300\n",
      "           4       0.14      0.12      0.13       300\n",
      "           5       0.08      0.05      0.07       300\n",
      "           6       0.14      0.09      0.11       300\n",
      "           7       0.18      0.11      0.14       298\n",
      "\n",
      "    accuracy                           0.17      2398\n",
      "   macro avg       0.16      0.17      0.16      2398\n",
      "weighted avg       0.16      0.17      0.16      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.18932443703085905\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.28      0.25       300\n",
      "           1       0.16      0.20      0.18       300\n",
      "           2       0.32      0.31      0.31       300\n",
      "           3       0.22      0.22      0.22       300\n",
      "           4       0.19      0.17      0.18       300\n",
      "           5       0.11      0.12      0.12       300\n",
      "           6       0.09      0.08      0.08       300\n",
      "           7       0.18      0.14      0.16       298\n",
      "\n",
      "    accuracy                           0.19      2398\n",
      "   macro avg       0.19      0.19      0.19      2398\n",
      "weighted avg       0.19      0.19      0.19      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.22018348623853212\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.42      0.33       300\n",
      "           1       0.23      0.29      0.26       300\n",
      "           2       0.31      0.30      0.30       300\n",
      "           3       0.25      0.26      0.26       300\n",
      "           4       0.17      0.14      0.15       300\n",
      "           5       0.09      0.09      0.09       300\n",
      "           6       0.16      0.11      0.13       300\n",
      "           7       0.24      0.16      0.19       298\n",
      "\n",
      "    accuracy                           0.22      2398\n",
      "   macro avg       0.21      0.22      0.21      2398\n",
      "weighted avg       0.21      0.22      0.21      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.21059216013344453\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.36      0.30       300\n",
      "           1       0.20      0.24      0.22       300\n",
      "           2       0.33      0.35      0.34       300\n",
      "           3       0.27      0.25      0.26       300\n",
      "           4       0.14      0.11      0.13       300\n",
      "           5       0.09      0.10      0.10       300\n",
      "           6       0.12      0.09      0.10       300\n",
      "           7       0.23      0.18      0.20       298\n",
      "\n",
      "    accuracy                           0.21      2398\n",
      "   macro avg       0.21      0.21      0.21      2398\n",
      "weighted avg       0.21      0.21      0.21      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 100
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
