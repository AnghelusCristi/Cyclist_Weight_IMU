{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Imports",
   "id": "309ecc50a1a4cfa9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:26.418199Z",
     "start_time": "2024-06-15T10:55:26.406199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "id": "a1aadba2ecadc4b3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:43.368998Z",
     "start_time": "2024-06-15T10:55:26.660193Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import only the low speed data\n",
    "df = pd.read_csv('../Data/combined_data.csv')\n",
    "df_low = df[df['speed'] == 0].copy()"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:43.723480Z",
     "start_time": "2024-06-15T10:55:43.376059Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Divide the data into classes based on weight.\n",
    "num_classes = 3 # Change for different nr. of classes.\n",
    "df_low.loc[:, 'weight_class'] = pd.qcut(df_low['weight'], q=num_classes, labels=False)"
   ],
   "id": "4c4b11fed90058be",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.050636Z",
     "start_time": "2024-06-15T10:55:43.727507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group the DataFrame by 'weight_class' and get unique 'weight' in each group\n",
    "weights_by_class= df_low.groupby('weight_class')['weight'].unique()\n",
    "\n",
    "print(weights_by_class)"
   ],
   "id": "2c990dba2b2bf45c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight_class\n",
      "0      [85.0, 86.6]\n",
      "1     [87.95, 89.2]\n",
      "2     [90.65, 91.8]\n",
      "3      [92.9, 94.4]\n",
      "4     [95.5, 96.55]\n",
      "5      [97.9, 99.1]\n",
      "6    [100.3, 101.5]\n",
      "7    [103.1, 104.5]\n",
      "Name: weight, dtype: object\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.113765Z",
     "start_time": "2024-06-15T10:55:44.055726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_test():\n",
    "    # Split the data into training and testing sets\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "    weights_by_class = df_low.groupby('weight_class')['weight'].unique()\n",
    "    \n",
    "    for weight_class, weights in weights_by_class.items():\n",
    "        weights = sorted(weights)\n",
    "        test_weights = [weights[0]]  # Select the testing weights\n",
    "        train_weights = [weight for i, weight in enumerate(weights) if i not in [0]]  # Exclude the testing weights\n",
    "        \n",
    "        df_test = pd.concat([df_test, df_low[(df_low['weight_class'] == weight_class) & (df_low['weight'].isin(test_weights))]], ignore_index=True)\n",
    "        for weight in train_weights:\n",
    "            df_train = pd.concat([df_train, df_low[(df_low['weight_class'] == weight_class) & (df_low['weight'] == weight)]], ignore_index=True)\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    return df_train, df_test"
   ],
   "id": "a1f5bb81ba4f1055",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract features",
   "id": "d3f8b73b9ebb5631"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.222783Z",
     "start_time": "2024-06-15T10:55:44.118958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feature extraction function\n",
    "# Credit to: https://towardsdatascience.com/feature-engineering-on-time-series-data-transforming-signal-data-of-a-smartphone-accelerometer-for-72cbe34b8a60\n",
    "\n",
    "def extract_features(df, window_size, step_size):\n",
    "    ax_list, ay_list, az_list, labels = [], [], [], []\n",
    "    for i in range(0, df.shape[0] - window_size, step_size):\n",
    "        axs = df['ax'].values[i: i + window_size]\n",
    "        ays = df['ay'].values[i: i + window_size]\n",
    "        azs = df['az'].values[i: i + window_size]\n",
    "        label = df['weight_class'].iloc[i: i + window_size].mode()[0]\n",
    "        \n",
    "        ax_list.append(axs)\n",
    "        ay_list.append(ays)\n",
    "        az_list.append(azs)\n",
    "        labels.append(label)\n",
    "    \n",
    "    X = pd.DataFrame()\n",
    "    \n",
    "    X['x_mean'] = pd.Series(ax_list).apply(lambda x: x.mean())\n",
    "    X['y_mean'] = pd.Series(ay_list).apply(lambda x: x.mean())\n",
    "    X['z_mean'] = pd.Series(az_list).apply(lambda x: x.mean())\n",
    "\n",
    "    X['x_std'] = pd.Series(ax_list).apply(lambda x: x.std())\n",
    "    X['y_std'] = pd.Series(ay_list).apply(lambda x: x.std())\n",
    "    X['z_std'] = pd.Series(az_list).apply(lambda x: x.std())\n",
    "\n",
    "    X['x_aad'] = pd.Series(ax_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['y_aad'] = pd.Series(ay_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['z_aad'] = pd.Series(az_list).apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "\n",
    "    X['x_min'] = pd.Series(ax_list).apply(lambda x: x.min())\n",
    "    X['y_min'] = pd.Series(ay_list).apply(lambda x: x.min())\n",
    "    X['z_min'] = pd.Series(az_list).apply(lambda x: x.min())\n",
    "\n",
    "    X['x_max'] = pd.Series(ax_list).apply(lambda x: x.max())\n",
    "    X['y_max'] = pd.Series(ay_list).apply(lambda x: x.max())\n",
    "    X['z_max'] = pd.Series(az_list).apply(lambda x: x.max())\n",
    "\n",
    "    X['x_maxmin_diff'] = X['x_max'] - X['x_min']\n",
    "    X['y_maxmin_diff'] = X['y_max'] - X['y_min']\n",
    "    X['z_maxmin_diff'] = X['z_max'] - X['z_min']\n",
    "    \n",
    "    X['x_median'] = pd.Series(ax_list).apply(lambda x: np.median(x))\n",
    "    X['y_median'] = pd.Series(ay_list).apply(lambda x: np.median(x))\n",
    "    X['z_median'] = pd.Series(az_list).apply(lambda x: np.median(x))\n",
    "    \n",
    "    X['x_mad'] = pd.Series(ax_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['y_mad'] = pd.Series(ay_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['z_mad'] = pd.Series(az_list).apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    \n",
    "    X['x_IQR'] = pd.Series(ax_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['y_IQR'] = pd.Series(ay_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['z_IQR'] = pd.Series(az_list).apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    \n",
    "    X['x_neg_count'] = pd.Series(ax_list).apply(lambda x: np.sum(x < 0))\n",
    "    X['y_neg_count'] = pd.Series(ay_list).apply(lambda x: np.sum(x < 0))\n",
    "    X['z_neg_count'] = pd.Series(az_list).apply(lambda x: np.sum(x < 0))\n",
    "    \n",
    "    X['x_pos_count'] = pd.Series(ax_list).apply(lambda x: np.sum(x > 0))\n",
    "    X['y_pos_count'] = pd.Series(ay_list).apply(lambda x: np.sum(x > 0))\n",
    "    X['z_pos_count'] = pd.Series(az_list).apply(lambda x: np.sum(x > 0))\n",
    "    \n",
    "    X['x_above_mean'] = pd.Series(ax_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['y_above_mean'] = pd.Series(ay_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['z_above_mean'] = pd.Series(az_list).apply(lambda x: np.sum(x > x.mean()))\n",
    "    \n",
    "    X['x_peak_count'] = pd.Series(ax_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['y_peak_count'] = pd.Series(ay_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['z_peak_count'] = pd.Series(az_list).apply(lambda x: len(find_peaks(x)[0]))\n",
    "    \n",
    "    X['x_skewness'] = pd.Series(ax_list).apply(lambda x: stats.skew(x))\n",
    "    X['y_skewness'] = pd.Series(ay_list).apply(lambda x: stats.skew(x))\n",
    "    X['z_skewness'] = pd.Series(az_list).apply(lambda x: stats.skew(x))\n",
    "    \n",
    "    X['x_kurtosis'] = pd.Series(ax_list).apply(lambda x: stats.kurtosis(x))\n",
    "    X['y_kurtosis'] = pd.Series(ay_list).apply(lambda x: stats.kurtosis(x))\n",
    "    X['z_kurtosis'] = pd.Series(az_list).apply(lambda x: stats.kurtosis(x))\n",
    "    \n",
    "    X['x_energy'] = pd.Series(ax_list).apply(lambda x: np.sum(x**2)/100)\n",
    "    X['y_energy'] = pd.Series(ay_list).apply(lambda x: np.sum(x**2)/100)\n",
    "    X['z_energy'] = pd.Series(az_list).apply(lambda x: np.sum(x**2/100))\n",
    "    \n",
    "    X['avg_result_accl'] = [i.mean() for i in ((pd.Series(ax_list)**2 + pd.Series(ay_list)**2 + pd.Series(az_list)**2)**0.5)]\n",
    "    X['sma'] = pd.Series(ax_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(ay_list).apply(lambda x: np.sum(abs(x)/100)) + pd.Series(az_list).apply(lambda x: np.sum(abs(x)/100))\n",
    "    \n",
    "    # FFT features\n",
    "    x_list_fft = pd.Series(ax_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    y_list_fft = pd.Series(ay_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    z_list_fft = pd.Series(az_list).apply(lambda x: np.abs(np.fft.fft(x))[1:51])\n",
    "    \n",
    "    X['x_mean_fft'] = x_list_fft.apply(lambda x: x.mean())\n",
    "    X['y_mean_fft'] = y_list_fft.apply(lambda x: x.mean())\n",
    "    X['z_mean_fft'] = z_list_fft.apply(lambda x: x.mean())\n",
    "    \n",
    "    X['x_std_fft'] = x_list_fft.apply(lambda x: x.std())\n",
    "    X['y_std_fft'] = y_list_fft.apply(lambda x: x.std())\n",
    "    X['z_std_fft'] = z_list_fft.apply(lambda x: x.std())\n",
    "    \n",
    "    X['x_aad_fft'] = x_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['y_aad_fft'] = y_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    X['z_aad_fft'] = z_list_fft.apply(lambda x: np.mean(np.absolute(x - np.mean(x))))\n",
    "    \n",
    "    X['x_min_fft'] = x_list_fft.apply(lambda x: x.min())\n",
    "    X['y_min_fft'] = y_list_fft.apply(lambda x: x.min())\n",
    "    X['z_min_fft'] = z_list_fft.apply(lambda x: x.min())\n",
    "    \n",
    "    X['x_max_fft'] = x_list_fft.apply(lambda x: x.max())\n",
    "    X['y_max_fft'] = y_list_fft.apply(lambda x: x.max())\n",
    "    X['z_max_fft'] = z_list_fft.apply(lambda x: x.max())\n",
    "    \n",
    "    X['x_maxmin_diff_fft'] = X['x_max_fft'] - X['x_min_fft']\n",
    "    X['y_maxmin_diff_fft'] = X['y_max_fft'] - X['y_min_fft']\n",
    "    X['z_maxmin_diff_fft'] = X['z_max_fft'] - X['z_min_fft']\n",
    "    \n",
    "    X['x_median_fft'] = x_list_fft.apply(lambda x: np.median(x))\n",
    "    X['y_median_fft'] = y_list_fft.apply(lambda x: np.median(x))\n",
    "    X['z_median_fft'] = z_list_fft.apply(lambda x: np.median(x))\n",
    "    \n",
    "    X['x_mad_fft'] = x_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['y_mad_fft'] = y_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    X['z_mad_fft'] = z_list_fft.apply(lambda x: np.median(np.absolute(x - np.median(x))))\n",
    "    \n",
    "    X['x_IQR_fft'] = x_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['y_IQR_fft'] = y_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    X['z_IQR_fft'] = z_list_fft.apply(lambda x: np.percentile(x, 75) - np.percentile(x, 25))\n",
    "    \n",
    "    X['x_above_mean_fft'] = x_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['y_above_mean_fft'] = y_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "    X['z_above_mean_fft'] = z_list_fft.apply(lambda x: np.sum(x > x.mean()))\n",
    "\n",
    "    X['x_peak_count_fft'] = x_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['y_peak_count_fft'] = y_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "    X['z_peak_count_fft'] = z_list_fft.apply(lambda x: len(find_peaks(x)[0]))\n",
    "\n",
    "    X['x_skewness_fft'] = x_list_fft.apply(lambda x: stats.skew(x))\n",
    "    X['y_skewness_fft'] = y_list_fft.apply(lambda x: stats.skew(x))\n",
    "    X['z_skewness_fft'] = z_list_fft.apply(lambda x: stats.skew(x))\n",
    "    \n",
    "    X['x_kurtosis_fft'] = x_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    X['y_kurtosis_fft'] = y_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    X['z_kurtosis_fft'] = z_list_fft.apply(lambda x: stats.kurtosis(x))\n",
    "    \n",
    "    X['x_energy_fft'] = x_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    X['y_energy_fft'] = y_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    X['z_energy_fft'] = z_list_fft.apply(lambda x: np.sum(x**2)/50)\n",
    "    \n",
    "    X['avg_result_accl_fft'] = [i.mean() for i in ((pd.Series(x_list_fft)**2 + pd.Series(y_list_fft)**2 + pd.Series(z_list_fft)**2)**0.5)]\n",
    "    \n",
    "    X['sma_fft'] = x_list_fft.apply(lambda x: np.sum(abs(x)/50)) + y_list_fft.apply(lambda x: np.sum(abs(x)/50)) + z_list_fft.apply(lambda x: np.sum(abs(x)/50))\n",
    "\n",
    "    # X['speed'] = df['speed']\n",
    "    # X['node-id'] = df['node-id']\n",
    "    \n",
    "    y = np.array(labels)\n",
    "    return X, y\n"
   ],
   "id": "16d9d7314a767aa4",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.238791Z",
     "start_time": "2024-06-15T10:55:44.225737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title, filename):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title(title)\n",
    "    plt.savefig(filename)\n",
    "    plt.close()"
   ],
   "id": "2b22a9dd554090a5",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.254327Z",
     "start_time": "2024-06-15T10:55:44.242822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def save_classification_report(y_true, y_pred, filename):\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(report)"
   ],
   "id": "3cef88b27b4296d3",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:55:44.270404Z",
     "start_time": "2024-06-15T10:55:44.257326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# creating overlapping windows of size window-size 400 (200 hz * 2 seconds = 400 frame windows for 2 seconds)\n",
    "window_size = 400\n",
    "step_size = int(window_size * 0.5)"
   ],
   "id": "4adf623c41e336ca",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Models",
   "id": "ce3e74df025cb404"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### All sensors",
   "id": "b8194c0e2c35d396"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:58:50.907176Z",
     "start_time": "2024-06-15T10:55:44.272938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "c6349f1bb103e71d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:59:26.630944Z",
     "start_time": "2024-06-15T10:58:50.913182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - All sensors', 'Results/Low_speed/{0} classes/knn_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/Low_speed/{0} classes/knn_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - All sensors', 'Results/Low_speed/{0} classes/dt_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/Low_speed/{0} classes/dt_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - All sensors', 'Results/Low_speed/{0} classes/svm_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/Low_speed/{0} classes/svm_all_sensors.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - All sensors', 'Results/Low_speed/{0} classes/lr_all_sensors.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/Low_speed/{0} classes/lr_all_sensors.txt'.format(num_classes))"
   ],
   "id": "15c1f2296ea7b394",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.1710197277021395\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.28      0.21       900\n",
      "           1       0.17      0.23      0.19       900\n",
      "           2       0.16      0.17      0.16       900\n",
      "           3       0.17      0.13      0.15       900\n",
      "           4       0.19      0.17      0.18       900\n",
      "           5       0.15      0.13      0.14       900\n",
      "           6       0.16      0.11      0.13       900\n",
      "           7       0.23      0.13      0.17       898\n",
      "\n",
      "    accuracy                           0.17      7198\n",
      "   macro avg       0.17      0.17      0.17      7198\n",
      "weighted avg       0.17      0.17      0.17      7198\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.24395665462628507\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.23      0.23       900\n",
      "           1       0.19      0.19      0.19       900\n",
      "           2       0.26      0.25      0.26       900\n",
      "           3       0.24      0.23      0.23       900\n",
      "           4       0.26      0.30      0.28       900\n",
      "           5       0.19      0.21      0.20       900\n",
      "           6       0.24      0.24      0.24       900\n",
      "           7       0.38      0.31      0.34       898\n",
      "\n",
      "    accuracy                           0.24      7198\n",
      "   macro avg       0.25      0.24      0.25      7198\n",
      "weighted avg       0.25      0.24      0.25      7198\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.19977771603223118\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.20       900\n",
      "           1       0.18      0.17      0.17       900\n",
      "           2       0.24      0.18      0.21       900\n",
      "           3       0.18      0.25      0.21       900\n",
      "           4       0.15      0.15      0.15       900\n",
      "           5       0.22      0.17      0.19       900\n",
      "           6       0.19      0.22      0.20       900\n",
      "           7       0.26      0.26      0.26       898\n",
      "\n",
      "    accuracy                           0.20      7198\n",
      "   macro avg       0.20      0.20      0.20      7198\n",
      "weighted avg       0.20      0.20      0.20      7198\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.19144206724090024\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.17      0.18       900\n",
      "           1       0.17      0.15      0.16       900\n",
      "           2       0.20      0.15      0.17       900\n",
      "           3       0.18      0.25      0.21       900\n",
      "           4       0.15      0.15      0.15       900\n",
      "           5       0.19      0.15      0.17       900\n",
      "           6       0.18      0.21      0.19       900\n",
      "           7       0.27      0.29      0.28       898\n",
      "\n",
      "    accuracy                           0.19      7198\n",
      "   macro avg       0.19      0.19      0.19      7198\n",
      "weighted avg       0.19      0.19      0.19      7198\n",
      "\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 561 - On the head tube",
   "id": "b78be4e164fbd18d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T10:59:29.339329Z",
     "start_time": "2024-06-15T10:59:26.632893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 561\n",
    "df_train = df_train[df_train['node-id'] == 561]\n",
    "df_test = df_test[df_test['node-id'] == 561]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "431a388b49180a92",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:00:27.317900Z",
     "start_time": "2024-06-15T10:59:29.342331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "6aa1187e3b0fd903",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:00:35.200287Z",
     "start_time": "2024-06-15T11:00:27.320903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 561', 'Results/Low_speed/{0} classes/knn_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/Low_speed/{0} classes/knn_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 561', 'Results/Low_speed/{0} classes/dt_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/Low_speed/{0} classes/dt_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 561', 'Results/Low_speed/{0} classes/svm_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/Low_speed/{0} classes/svm_sensor_561.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 561', 'Results/Low_speed/{0} classes/lr_sensor_561.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/Low_speed/{0} classes/lr_sensor_561.txt'.format(num_classes))"
   ],
   "id": "2dfb566c693e9298",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.18223519599666388\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.30      0.23       300\n",
      "           1       0.16      0.24      0.19       300\n",
      "           2       0.17      0.16      0.16       300\n",
      "           3       0.20      0.12      0.15       300\n",
      "           4       0.20      0.20      0.20       300\n",
      "           5       0.16      0.17      0.16       300\n",
      "           6       0.22      0.13      0.16       300\n",
      "           7       0.22      0.15      0.18       298\n",
      "\n",
      "    accuracy                           0.18      2398\n",
      "   macro avg       0.19      0.18      0.18      2398\n",
      "weighted avg       0.19      0.18      0.18      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.20391993327773145\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.18      0.17       300\n",
      "           1       0.20      0.23      0.22       300\n",
      "           2       0.26      0.25      0.25       300\n",
      "           3       0.33      0.26      0.29       300\n",
      "           4       0.12      0.12      0.12       300\n",
      "           5       0.16      0.19      0.18       300\n",
      "           6       0.19      0.17      0.18       300\n",
      "           7       0.25      0.22      0.24       298\n",
      "\n",
      "    accuracy                           0.20      2398\n",
      "   macro avg       0.21      0.20      0.21      2398\n",
      "weighted avg       0.21      0.20      0.21      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.2468723936613845\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.29      0.26       300\n",
      "           1       0.22      0.24      0.23       300\n",
      "           2       0.34      0.30      0.32       300\n",
      "           3       0.38      0.24      0.30       300\n",
      "           4       0.16      0.16      0.16       300\n",
      "           5       0.19      0.25      0.22       300\n",
      "           6       0.20      0.17      0.18       300\n",
      "           7       0.34      0.31      0.33       298\n",
      "\n",
      "    accuracy                           0.25      2398\n",
      "   macro avg       0.26      0.25      0.25      2398\n",
      "weighted avg       0.26      0.25      0.25      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.2652210175145955\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.29      0.28       300\n",
      "           1       0.21      0.23      0.22       300\n",
      "           2       0.33      0.30      0.32       300\n",
      "           3       0.40      0.31      0.35       300\n",
      "           4       0.19      0.16      0.17       300\n",
      "           5       0.21      0.28      0.24       300\n",
      "           6       0.19      0.18      0.19       300\n",
      "           7       0.35      0.36      0.36       298\n",
      "\n",
      "    accuracy                           0.27      2398\n",
      "   macro avg       0.27      0.27      0.27      2398\n",
      "weighted avg       0.27      0.27      0.27      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 562 - Under the seat",
   "id": "cece8dfa68b0d20c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:00:38.091726Z",
     "start_time": "2024-06-15T11:00:35.203297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 562\n",
    "df_train = df_train[df_train['node-id'] == 562]\n",
    "df_test = df_test[df_test['node-id'] == 562]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "633ba1a4c2599889",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:01:44.375607Z",
     "start_time": "2024-06-15T11:00:38.095723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "25d671e043b60556",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:01:53.103138Z",
     "start_time": "2024-06-15T11:01:44.381684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 562', 'Results/Low_speed/{0} classes/knn_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/Low_speed/{0} classes/knn_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 562', 'Results/Low_speed/{0} classes/dt_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/Low_speed/{0} classes/dt_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 562', 'Results/Low_speed/{0} classes/svm_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/Low_speed/{0} classes/svm_sensor_562.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 562', 'Results/Low_speed/{0} classes/lr_sensor_562.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/Low_speed/{0} classes/lr_sensor_562.txt'.format(num_classes))"
   ],
   "id": "13aeb9a8057c3981",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.2731442869057548\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.35      0.29       300\n",
      "           1       0.22      0.29      0.25       300\n",
      "           2       0.23      0.22      0.23       300\n",
      "           3       0.25      0.23      0.24       300\n",
      "           4       0.34      0.41      0.37       300\n",
      "           5       0.24      0.29      0.26       300\n",
      "           6       0.27      0.20      0.23       300\n",
      "           7       0.70      0.19      0.30       298\n",
      "\n",
      "    accuracy                           0.27      2398\n",
      "   macro avg       0.31      0.27      0.27      2398\n",
      "weighted avg       0.31      0.27      0.27      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.36905754795663054\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.35      0.34       300\n",
      "           1       0.24      0.23      0.23       300\n",
      "           2       0.27      0.28      0.27       300\n",
      "           3       0.35      0.37      0.36       300\n",
      "           4       0.43      0.63      0.51       300\n",
      "           5       0.35      0.34      0.34       300\n",
      "           6       0.37      0.34      0.35       300\n",
      "           7       0.83      0.42      0.56       298\n",
      "\n",
      "    accuracy                           0.37      2398\n",
      "   macro avg       0.39      0.37      0.37      2398\n",
      "weighted avg       0.39      0.37      0.37      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.37155963302752293\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.46      0.40       300\n",
      "           1       0.24      0.26      0.25       300\n",
      "           2       0.29      0.27      0.28       300\n",
      "           3       0.32      0.32      0.32       300\n",
      "           4       0.45      0.65      0.53       300\n",
      "           5       0.36      0.34      0.35       300\n",
      "           6       0.34      0.32      0.33       300\n",
      "           7       0.91      0.36      0.52       298\n",
      "\n",
      "    accuracy                           0.37      2398\n",
      "   macro avg       0.41      0.37      0.37      2398\n",
      "weighted avg       0.41      0.37      0.37      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.3640533778148457\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39       300\n",
      "           1       0.23      0.22      0.22       300\n",
      "           2       0.26      0.24      0.25       300\n",
      "           3       0.26      0.29      0.27       300\n",
      "           4       0.47      0.60      0.53       300\n",
      "           5       0.39      0.39      0.39       300\n",
      "           6       0.33      0.33      0.33       300\n",
      "           7       0.82      0.41      0.55       298\n",
      "\n",
      "    accuracy                           0.36      2398\n",
      "   macro avg       0.39      0.36      0.37      2398\n",
      "weighted avg       0.39      0.36      0.37      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Sensor 563 - Rear frame",
   "id": "bd6dbb3ebeac6d0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:01:56.059433Z",
     "start_time": "2024-06-15T11:01:53.106113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_train, df_test = train_test()\n",
    "# Now only use the node-id 563\n",
    "df_train = df_train[df_train['node-id'] == 563]\n",
    "df_test = df_test[df_test['node-id'] == 563]\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ],
   "id": "6d9808077282e9fd",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:02:57.569578Z",
     "start_time": "2024-06-15T11:01:56.062373Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, y_train = extract_features(df_train, window_size, step_size)\n",
    "X_test, y_test = extract_features(df_test, window_size, step_size)\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "46dbe70d92a9bb8f",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T11:03:04.982890Z",
     "start_time": "2024-06-15T11:02:57.571783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# KNN model\n",
    "knn_model = KNeighborsClassifier(n_jobs=1) # Create KNN model\n",
    "knn_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_knn = knn_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"KNN Model:\")\n",
    "print(\"Accuracy:\", accuracy_knn)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_knn, 'KNN - Sensor 563', 'Results/Low_speed/{0} classes/knn_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_knn, 'Results/Low_speed/{0} classes/knn_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# Decision Tree model\n",
    "dt_model = DecisionTreeClassifier(random_state=42) # Create Decision Tree model\n",
    "dt_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_dt = dt_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Model:\")\n",
    "print(\"Accuracy:\", accuracy_dt)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_dt, 'Decision Tree - Sensor 563', 'Results/Low_speed/{0} classes/dt_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_dt, 'Results/Low_speed/{0} classes/dt_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# SVM model\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # Create SVM model\n",
    "svm_model.fit(X_train, y_train) # Fit the model\n",
    "y_pred_svm = svm_model.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Model:\")\n",
    "print(\"Accuracy:\", accuracy_svm)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred_svm, 'SVM - Sensor 563', 'Results/Low_speed/{0} classes/svm_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred_svm, 'Results/Low_speed/{0} classes/svm_sensor_563.txt'.format(num_classes))\n",
    "\n",
    "# Logistic Regression model\n",
    "model_lr = LogisticRegression(max_iter=1000, random_state=42) # Create Logistic Regression model\n",
    "model_lr.fit(X_train, y_train) # Fit the model\n",
    "y_pred = model_lr.predict(X_test) # Make predictions\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_lr = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Model:\")\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "print(\"\\n -------------Classification Report-------------\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the results\n",
    "plot_confusion_matrix(y_test, y_pred, 'Logistic Regression - Sensor 563', 'Results/Low_speed/{0} classes/lr_sensor_563.png'.format(num_classes))\n",
    "save_classification_report(y_test, y_pred, 'Results/Low_speed/{0} classes/lr_sensor_563.txt'.format(num_classes))"
   ],
   "id": "57803fbb2a5cdf61",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model:\n",
      "Accuracy: 0.18181818181818182\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.21      0.17       300\n",
      "           1       0.15      0.19      0.17       300\n",
      "           2       0.17      0.20      0.18       300\n",
      "           3       0.15      0.10      0.12       300\n",
      "           4       0.23      0.23      0.23       300\n",
      "           5       0.23      0.18      0.20       300\n",
      "           6       0.17      0.17      0.17       300\n",
      "           7       0.24      0.18      0.21       298\n",
      "\n",
      "    accuracy                           0.18      2398\n",
      "   macro avg       0.19      0.18      0.18      2398\n",
      "weighted avg       0.19      0.18      0.18      2398\n",
      "\n",
      "Decision Tree Model:\n",
      "Accuracy: 0.1663886572143453\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.18      0.17       300\n",
      "           1       0.14      0.13      0.14       300\n",
      "           2       0.22      0.18      0.20       300\n",
      "           3       0.08      0.09      0.09       300\n",
      "           4       0.21      0.19      0.20       300\n",
      "           5       0.16      0.16      0.16       300\n",
      "           6       0.13      0.15      0.14       300\n",
      "           7       0.25      0.25      0.25       298\n",
      "\n",
      "    accuracy                           0.17      2398\n",
      "   macro avg       0.17      0.17      0.17      2398\n",
      "weighted avg       0.17      0.17      0.17      2398\n",
      "\n",
      "SVM Model:\n",
      "Accuracy: 0.22018348623853212\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.30      0.27       300\n",
      "           1       0.14      0.12      0.13       300\n",
      "           2       0.16      0.15      0.16       300\n",
      "           3       0.15      0.15      0.15       300\n",
      "           4       0.25      0.21      0.23       300\n",
      "           5       0.20      0.21      0.21       300\n",
      "           6       0.20      0.23      0.22       300\n",
      "           7       0.42      0.39      0.41       298\n",
      "\n",
      "    accuracy                           0.22      2398\n",
      "   macro avg       0.22      0.22      0.22      2398\n",
      "weighted avg       0.22      0.22      0.22      2398\n",
      "\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.20809007506255212\n",
      "\n",
      " -------------Classification Report-------------\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.24      0.23       300\n",
      "           1       0.15      0.14      0.14       300\n",
      "           2       0.13      0.10      0.11       300\n",
      "           3       0.14      0.17      0.16       300\n",
      "           4       0.20      0.16      0.18       300\n",
      "           5       0.18      0.19      0.18       300\n",
      "           6       0.20      0.24      0.22       300\n",
      "           7       0.42      0.44      0.43       298\n",
      "\n",
      "    accuracy                           0.21      2398\n",
      "   macro avg       0.21      0.21      0.21      2398\n",
      "weighted avg       0.21      0.21      0.21      2398\n",
      "\n"
     ]
    }
   ],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
